{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d91a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5226393",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '/home/saran/Desktop/Codes/image_sticher/test_images/test1'\n",
    "\n",
    "images = []\n",
    "\n",
    "for img in os.listdir(img_dir):\n",
    "    img = cv2.imread(img_dir + '/' + img)\n",
    "\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    if len(img.shape) != 3:\n",
    "        print(f\"a valid image format\")        \n",
    "\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b3863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough good matches for image 0 (37 found)\n",
      "Not enough good matches for image 1 (24 found)\n",
      "Not enough good matches for image 2 (16 found)\n",
      "Not enough good matches for image 3 (31 found)\n",
      "Not enough good matches for image 6 (24 found)\n",
      "Not enough good matches for image 7 (21 found)\n",
      "Not enough good matches for image 8 (19 found)\n",
      "Not enough good matches for image 10 (19 found)\n",
      "Not enough good matches for image 11 (42 found)\n",
      "Not enough good matches for image 12 (14 found)\n",
      "Not enough good matches for image 13 (39 found)\n",
      "Not enough good matches for image 14 (21 found)\n",
      "Not enough good matches for image 15 (17 found)\n",
      "Not enough good matches for image 16 (32 found)\n",
      "Not enough good matches for image 17 (17 found)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_matches = 100 # the min number of common matches between two images for them to be stiched\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "base_idx = len(images) // 2\n",
    "base_img = images[base_idx]\n",
    "base_img = cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "keys_base, des_base = sift.detectAndCompute(base_img, None)\n",
    "\n",
    "# stores the homography matrcies\n",
    "homos = {base_idx: np.eye(3)}\n",
    "\n",
    "for i in range(len(images)):\n",
    "    if i == base_idx:\n",
    "        continue\n",
    "\n",
    "    img = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\n",
    "    keys, des = sift.detectAndCompute(img, None)\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # find the best matches\n",
    "    for idx1, d1 in enumerate(des):\n",
    "        dists = np.linalg.norm(des_base - d1, axis=1)\n",
    "        nn_idx = np.argsort(dists)[:2]\n",
    "        m, n = dists[nn_idx[0]], dists[nn_idx[1]]\n",
    "\n",
    "        if n!=0 and m/n < 0.75:\n",
    "            matches.append((nn_idx[0], idx1))\n",
    "\n",
    "    # get the images with most matches\n",
    "    if len(matches) > min_matches:\n",
    "        src_pts = np.float32([keys[idx2].pt for _, idx2 in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keys_base[idx1].pt for idx1, _ in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        if H is not None:\n",
    "            homos[i] = H\n",
    "        else:\n",
    "            print(f\"Homography for image {i} failed.\")\n",
    "    else:\n",
    "        print(f\"Not enough good matches for image {i} ({len(matches)} found)\")\n",
    "\n",
    "# prepare the canvas\n",
    "height = base_img.shape[0]\n",
    "width = base_img.shape[1]\n",
    "corners = np.float32([[0, 0], [0, height], [width, height], [width, 0]]).reshape(-1, 1, 2)\n",
    "all_corners = []\n",
    "\n",
    "for i, H in homos.items():\n",
    "    warped_corners = cv2.perspectiveTransform(corners, H)\n",
    "    all_corners.append(warped_corners)\n",
    "\n",
    "all_corners = np.concatenate(all_corners, axis=0)\n",
    "[x_min, y_min] = np.int32(all_corners.min(axis=0).ravel() - 0.5)\n",
    "[x_max, y_max] = np.int32(all_corners.max(axis=0).ravel() + 0.5)\n",
    "\n",
    "offset = [-x_min, -y_min]\n",
    "canvas_shape = (y_max - y_min, x_max - x_min, 3)\n",
    "result = np.zeros(canvas_shape, dtype=np.uint8)\n",
    "\n",
    "# stiching the images\n",
    "for i, H in homos.items():\n",
    "    img = images[i]\n",
    "    H_offset = np.eye(3)\n",
    "    H_offset[:2, 2] = offset\n",
    "    full_H = H_offset @ H\n",
    "\n",
    "    warped = cv2.warpPerspective(img, full_H, (canvas_shape[1], canvas_shape[0]))\n",
    "    mask = (warped > 0).astype(np.uint8)\n",
    "    result = np.where(mask, warped, result)\n",
    "\n",
    "cv2.imwrite(\"./test_images/stitched_panorama.jpg\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
